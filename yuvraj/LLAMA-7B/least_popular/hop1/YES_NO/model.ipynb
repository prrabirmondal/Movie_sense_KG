{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee57007802bf4eb28627557e28fcc3a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"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\")\n",
    "chat_tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n",
    "chat_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Skyline_2010_summary.csv:  17%|█▋        | 1/6 [00:39<03:17, 39.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[inst] <<sys>>\n",
      "        you have a good knowledge of hollywood movies. you will be given a question\n",
      "        about a particular hollywood movie. using your knowledge, give answer as yes or no only for the given question.\n",
      "        don't let the previous responses affect this response.\n",
      "        <</sys>>\n",
      "        was 'a haunted house 2 2014' confirmed to be released on march 28, 2014? [/inst]\n",
      "        yes\n",
      "        [inst] did the principal photography and production for 'a haunted house 2 2014' begin in 2015? [/inst]\n",
      "        no\n",
      "        [inst] [\"is the movie 'skyline 2010' devoid of a summary that provides an overview of its plot, themes, and other important details?\"] [/inst]\n",
      "     no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Skyline_2010_summary.csv:  33%|███▎      | 2/6 [01:01<01:56, 29.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[inst] <<sys>>\n",
      "        you have a good knowledge of hollywood movies. you will be given a question\n",
      "        about a particular hollywood movie. using your knowledge, give answer as yes or no only for the given question.\n",
      "        don't let the previous responses affect this response.\n",
      "        <</sys>>\n",
      "        was 'a haunted house 2 2014' confirmed to be released on march 28, 2014? [/inst]\n",
      "        yes\n",
      "        [inst] did the principal photography and production for 'a haunted house 2 2014' begin in 2015? [/inst]\n",
      "        no\n",
      "        [inst] [\"does the movie 'skyline 2010' consist of a summary that provides an overview of its plot, themes, and other important details?\"] [/inst]\n",
      "     no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Skyline_2010_summary.csv:  50%|█████     | 3/6 [01:18<01:11, 23.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[inst] <<sys>>\n",
      "        you have a good knowledge of hollywood movies. you will be given a question\n",
      "        about a particular hollywood movie. using your knowledge, give answer as yes or no only for the given question.\n",
      "        don't let the previous responses affect this response.\n",
      "        <</sys>>\n",
      "        was 'a haunted house 2 2014' confirmed to be released on march 28, 2014? [/inst]\n",
      "        yes\n",
      "        [inst] did the principal photography and production for 'a haunted house 2 2014' begin in 2015? [/inst]\n",
      "        no\n",
      "        [inst] does the summary of \"skyline 2010\" exclude any details about the events and characters in the movie? [/inst]\n",
      "     no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Skyline_2010_summary.csv:  67%|██████▋   | 4/6 [01:35<00:41, 20.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[inst] <<sys>>\n",
      "        you have a good knowledge of hollywood movies. you will be given a question\n",
      "        about a particular hollywood movie. using your knowledge, give answer as yes or no only for the given question.\n",
      "        don't let the previous responses affect this response.\n",
      "        <</sys>>\n",
      "        was 'a haunted house 2 2014' confirmed to be released on march 28, 2014? [/inst]\n",
      "        yes\n",
      "        [inst] did the principal photography and production for 'a haunted house 2 2014' begin in 2015? [/inst]\n",
      "        no\n",
      "        [inst] does the summary of \"skyline 2010\" provide more specific information about the events and characters in the movie? [/inst]\n",
      "     no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Skyline_2010_summary.csv:  83%|████████▎ | 5/6 [01:51<00:19, 19.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[inst] <<sys>>\n",
      "        you have a good knowledge of hollywood movies. you will be given a question\n",
      "        about a particular hollywood movie. using your knowledge, give answer as yes or no only for the given question.\n",
      "        don't let the previous responses affect this response.\n",
      "        <</sys>>\n",
      "        was 'a haunted house 2 2014' confirmed to be released on march 28, 2014? [/inst]\n",
      "        yes\n",
      "        [inst] did the principal photography and production for 'a haunted house 2 2014' begin in 2015? [/inst]\n",
      "        no\n",
      "        [inst] [\"does the message displayed in 'skyline 2010' indicate that a user has accessed the details of a different movie's summary?\"] [/inst]\n",
      "     no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Skyline_2010_summary.csv: 100%|██████████| 6/6 [02:08<00:00, 21.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[inst] <<sys>>\n",
      "        you have a good knowledge of hollywood movies. you will be given a question\n",
      "        about a particular hollywood movie. using your knowledge, give answer as yes or no only for the given question.\n",
      "        don't let the previous responses affect this response.\n",
      "        <</sys>>\n",
      "        was 'a haunted house 2 2014' confirmed to be released on march 28, 2014? [/inst]\n",
      "        yes\n",
      "        [inst] did the principal photography and production for 'a haunted house 2 2014' begin in 2015? [/inst]\n",
      "        no\n",
      "        [inst] [\"when a message is displayed in 'skyline 2010', can it indicate that a user has accessed the details of this particular movie's summary?\"] [/inst]\n",
      "     no\n",
      "Skipping already processed file: A Haunted House 2_2014_Production.csv, Accuracy: 0.5\n",
      "Skipping already processed file: The Wicker Man_2006_Plot.csv, Accuracy: 0.5\n",
      "Processing complete. Check the output directory for results and report.txt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "# from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "input_dir = '/mnt/Data/prabirmondal/prabir/python_program/movie_sense/SRI_KG/Movie_sense_KG/Movie_sense_KG/yuvraj/yes no sample input'\n",
    "output_dir = '/mnt/Data/prabirmondal/prabir/python_program/movie_sense/SRI_KG/Movie_sense_KG/Movie_sense_KG/yuvraj/yes no sample output'\n",
    "report_path = os.path.join(output_dir, 'report_popular.txt')\n",
    "\n",
    "\n",
    "\n",
    "def filter(response):\n",
    "    # Split response into separate lines to find each instruction-answer pair\n",
    "    lines = response.lower().splitlines()\n",
    "    \n",
    "    # Initialize a variable to hold the last valid answer\n",
    "    final_answer = None\n",
    "    \n",
    "    # Iterate through lines to find 'yes' or 'no' answers\n",
    "    for line in lines:\n",
    "        line = line.strip()  # Remove whitespace\n",
    "        # Check if the line is exactly 'yes' or 'no' and update the final answer\n",
    "        if line == \"yes\" or line == \"no\":\n",
    "            final_answer = line\n",
    "\n",
    "    # Return the last valid 'yes' or 'no' found, or None if not found\n",
    "    return final_answer\n",
    "\n",
    "def generate_response(question):\n",
    "    prompt = f'''\n",
    "        [INST] <<SYS>>\n",
    "        You have a good knowledge of hollywood movies. You will be given a question\n",
    "        about a particular hollywood movie. Using your knowledge, Give answer as yes or no only for the given question.\n",
    "        Don't let the previous responses affect this response.\n",
    "        <</SYS>>\n",
    "        Was 'A Haunted House 2 2014' confirmed to be released on March 28, 2014? [/INST]\n",
    "        yes\n",
    "        [INST] Did the principal photography and production for 'A Haunted House 2 2014' begin in 2015? [/INST]\n",
    "        no\n",
    "        [INST] {question} [/INST]\n",
    "    '''\n",
    "    \n",
    "    inputs = chat_tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = chat_model.generate(**inputs, max_new_tokens=100, temperature=0.0001)\n",
    "    response = chat_tokenizer.decode(outputs[0], skip_special_tokens=True).strip().lower()\n",
    "    print(response)\n",
    "    return filter(response)\n",
    "# Define custom accuracy calculation function\n",
    "def calculate_accuracy(true_answers, predictions):\n",
    "    correct = sum(1 for true, pred in zip(true_answers, predictions) if true == pred)\n",
    "    return correct / len(true_answers) if true_answers else 0\n",
    "\n",
    "type_accuracies = {}\n",
    "overall_accuracies = []\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith('.csv'):\n",
    "        input_file_path = os.path.join(input_dir, filename)\n",
    "        output_file_path = os.path.join(output_dir, filename)\n",
    "        \n",
    "        # Extract the type from the filename\n",
    "        file_type = filename.split('_')[-1].split('.')[0].lower()\n",
    "\n",
    "        # Check if the output file already exists\n",
    "        if os.path.exists(output_file_path):\n",
    "            # If already processed, read the last accuracy value directly\n",
    "            existing_data = pd.read_csv(output_file_path)\n",
    "            file_accuracy = float(existing_data.iloc[-1, 2])  # Assuming last row, third column stores the accuracy\n",
    "            overall_accuracies.append(file_accuracy)\n",
    "            \n",
    "            if file_type not in type_accuracies:\n",
    "                type_accuracies[file_type] = []\n",
    "            type_accuracies[file_type].append(file_accuracy)\n",
    "            \n",
    "            # Skip further processing for this file\n",
    "            print(f\"Skipping already processed file: {filename}, Accuracy: {file_accuracy}\")\n",
    "            continue\n",
    "\n",
    "        # Read the input data and make predictions\n",
    "        data = pd.read_csv(input_file_path)\n",
    "        predictions = []\n",
    "        true_answers = data['Answer'].tolist()\n",
    "        \n",
    "        for question in tqdm(data['Question'], desc=f\"Processing {filename}\"):\n",
    "            response = generate_response(question)\n",
    "            predictions.append(response)\n",
    "        \n",
    "        # Calculate accuracy and add to overall and type-specific lists\n",
    "        file_accuracy = calculate_accuracy(true_answers, predictions)\n",
    "        overall_accuracies.append(file_accuracy)\n",
    "        \n",
    "        if file_type not in type_accuracies:\n",
    "            type_accuracies[file_type] = []\n",
    "        type_accuracies[file_type].append(file_accuracy)\n",
    "\n",
    "        # Save predictions and accuracy to CSV\n",
    "        data['LLAMA_response'] = predictions\n",
    "        data.loc[len(data)] = [\"\", \"\", file_accuracy]  # Assuming the last column is for accuracy\n",
    "        data.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Calculate average accuracy per type and overall accuracy\n",
    "report_content = []\n",
    "for file_type, accuracies in type_accuracies.items():\n",
    "    avg_type_accuracy = sum(accuracies) / len(accuracies)\n",
    "    report_content.append(f\"{file_type.capitalize()} Accuracy: {avg_type_accuracy:.2f}\")\n",
    "\n",
    "overall_accuracy = sum(overall_accuracies) / len(overall_accuracies) if overall_accuracies else 0\n",
    "report_content.append(f\"Overall Accuracy: {overall_accuracy:.2f}\")\n",
    "\n",
    "# Write the report to file\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(\"\\n\".join(report_content))\n",
    "\n",
    "print(\"Processing complete. Check the output directory for results and report.txt.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
